{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Entity Extraction Batch API \u00b6 A comprehensive entity extraction and knowledge API with Wikipedia linking, educational content generation, and question-answer pair creation. Features \u00b6 Entity Extraction : Extract or generate entities from text using OpenAI-compatible LLMs Wikipedia Linking : Intelligent entity linking with fallback strategies Educational Content : Generate comprehensive educational content (Compendium) Q&A Generation : Create question-answer pairs from content Pipeline Orchestration : End-to-end processing in a single API call Quick Start \u00b6 Installation \u00b6 # Clone the repository git clone https://github.com/your-org/entityextractorbatch.git cd entityextractorbatch # Install dependencies pip install -e \".[dev]\" # Set up environment variables export OPENAI_API_KEY = \"your-openai-api-key\" # Run the application uvicorn app.main:app --reload Docker \u00b6 # Build and run with Docker docker build -t entityextractorbatch . docker run -p 8000 :8000 -e OPENAI_API_KEY = \"your-key\" entityextractorbatch API Endpoints \u00b6 /api/v1/linker - Entity extraction and Wikipedia linking /api/v1/compendium - Educational content generation /api/v1/qa - Question-answer pair generation /api/v1/pipeline - Complete pipeline orchestration /health - Health check endpoint Interactive Documentation \u00b6 Visit /docs for Swagger UI or /redoc for ReDoc when the application is running. Architecture \u00b6 The application follows a modular architecture with clear separation of concerns: API Layer : FastAPI endpoints with Pydantic validation Core Logic : Business logic for entity processing, content generation Services : External service integrations (Wikipedia, OpenAI) Models : Data models and schemas Development \u00b6 See the Development Guide for detailed setup instructions and contribution guidelines.","title":"Home"},{"location":"#entity-extraction-batch-api","text":"A comprehensive entity extraction and knowledge API with Wikipedia linking, educational content generation, and question-answer pair creation.","title":"Entity Extraction Batch API"},{"location":"#features","text":"Entity Extraction : Extract or generate entities from text using OpenAI-compatible LLMs Wikipedia Linking : Intelligent entity linking with fallback strategies Educational Content : Generate comprehensive educational content (Compendium) Q&A Generation : Create question-answer pairs from content Pipeline Orchestration : End-to-end processing in a single API call","title":"Features"},{"location":"#quick-start","text":"","title":"Quick Start"},{"location":"#installation","text":"# Clone the repository git clone https://github.com/your-org/entityextractorbatch.git cd entityextractorbatch # Install dependencies pip install -e \".[dev]\" # Set up environment variables export OPENAI_API_KEY = \"your-openai-api-key\" # Run the application uvicorn app.main:app --reload","title":"Installation"},{"location":"#docker","text":"# Build and run with Docker docker build -t entityextractorbatch . docker run -p 8000 :8000 -e OPENAI_API_KEY = \"your-key\" entityextractorbatch","title":"Docker"},{"location":"#api-endpoints","text":"/api/v1/linker - Entity extraction and Wikipedia linking /api/v1/compendium - Educational content generation /api/v1/qa - Question-answer pair generation /api/v1/pipeline - Complete pipeline orchestration /health - Health check endpoint","title":"API Endpoints"},{"location":"#interactive-documentation","text":"Visit /docs for Swagger UI or /redoc for ReDoc when the application is running.","title":"Interactive Documentation"},{"location":"#architecture","text":"The application follows a modular architecture with clear separation of concerns: API Layer : FastAPI endpoints with Pydantic validation Core Logic : Business logic for entity processing, content generation Services : External service integrations (Wikipedia, OpenAI) Models : Data models and schemas","title":"Architecture"},{"location":"#development","text":"See the Development Guide for detailed setup instructions and contribution guidelines.","title":"Development"},{"location":"api/endpoints/","text":"API Endpoints \u00b6 Linker Endpoint \u00b6 POST /api/v1/linker \u00b6 Extract entities from text and link them to Wikipedia articles. Request Body: { \"text\" : \"Einstein entwickelte die Relativit\u00e4tstheorie\" , \"config\" : { \"MODE\" : \"extract\" , \"MAX_ENTITIES\" : 10 , \"ALLOWED_ENTITY_TYPES\" : [ \"PERSON\" , \"CONCEPT\" ], \"EDUCATIONAL_MODE\" : true , \"LANGUAGE\" : \"de\" } } Response: { \"entities\" : [ { \"entity\" : \"Albert Einstein\" , \"details\" : \"German-born theoretical physicist\" , \"sources\" : { \"wikipedia\" : { \"url_de\" : \"https://de.wikipedia.org/wiki/Albert_Einstein\" , \"extract\" : \"Albert Einstein war ein deutscher...\" , \"wikidata_id\" : \"Q937\" } }, \"id\" : \"entity_1\" } ], \"metadata\" : { \"total_entities\" : 1 , \"processing_mode\" : \"extract\" , \"language\" : \"de\" } } Compendium Endpoint \u00b6 POST /api/v1/compendium \u00b6 Generate educational content from entity data. Request Body: { \"entities\" : [ ... ], \"config\" : { \"length\" : 5000 , \"enable_citations\" : true , \"educational_mode\" : true , \"language\" : \"de\" } } QA Endpoint \u00b6 POST /api/v1/qa \u00b6 Generate question-answer pairs from markdown content. Request Body: { \"markdown_content\" : \"# Einstein\\n\\nAlbert Einstein war...\" , \"config\" : { \"num_pairs\" : 10 , \"max_answer_length\" : 200 } } Pipeline Endpoint \u00b6 POST /api/v1/pipeline \u00b6 Complete end-to-end processing combining all three endpoints. Request Body: { \"text\" : \"Input text for processing\" , \"config\" : { \"linker\" : { \"MODE\" : \"generate\" , \"MAX_ENTITIES\" : 15 }, \"compendium\" : { \"length\" : 8000 , \"enable_citations\" : true }, \"qa\" : { \"num_pairs\" : 12 , \"max_answer_length\" : 300 } } } Response: { \"original_text\" : \"Input text\" , \"linker_output\" : { ... }, \"compendium_output\" : { ... }, \"qa_output\" : { ... }, \"pipeline_statistics\" : { \"total_processing_time\" : 45.2 , \"steps_completed\" : 3 , \"step_times\" : { \"linker\" : 12.3 , \"compendium\" : 28.1 , \"qa\" : 4.8 } } } Utils Endpoints \u00b6 POST /api/v1/utils/synonyms \u00b6 Generate synonyms for a given term. Request Body: { \"term\" : \"Wissenschaft\" , \"max_synonyms\" : 5 } Response: { \"term\" : \"Wissenschaft\" , \"synonyms\" : [ \"Forschung\" , \"Wissenschaftlichkeit\" , \"Gelehrsamkeit\" ] }","title":"Endpoints"},{"location":"api/endpoints/#api-endpoints","text":"","title":"API Endpoints"},{"location":"api/endpoints/#linker-endpoint","text":"","title":"Linker Endpoint"},{"location":"api/endpoints/#post-apiv1linker","text":"Extract entities from text and link them to Wikipedia articles. Request Body: { \"text\" : \"Einstein entwickelte die Relativit\u00e4tstheorie\" , \"config\" : { \"MODE\" : \"extract\" , \"MAX_ENTITIES\" : 10 , \"ALLOWED_ENTITY_TYPES\" : [ \"PERSON\" , \"CONCEPT\" ], \"EDUCATIONAL_MODE\" : true , \"LANGUAGE\" : \"de\" } } Response: { \"entities\" : [ { \"entity\" : \"Albert Einstein\" , \"details\" : \"German-born theoretical physicist\" , \"sources\" : { \"wikipedia\" : { \"url_de\" : \"https://de.wikipedia.org/wiki/Albert_Einstein\" , \"extract\" : \"Albert Einstein war ein deutscher...\" , \"wikidata_id\" : \"Q937\" } }, \"id\" : \"entity_1\" } ], \"metadata\" : { \"total_entities\" : 1 , \"processing_mode\" : \"extract\" , \"language\" : \"de\" } }","title":"POST /api/v1/linker"},{"location":"api/endpoints/#compendium-endpoint","text":"","title":"Compendium Endpoint"},{"location":"api/endpoints/#post-apiv1compendium","text":"Generate educational content from entity data. Request Body: { \"entities\" : [ ... ], \"config\" : { \"length\" : 5000 , \"enable_citations\" : true , \"educational_mode\" : true , \"language\" : \"de\" } }","title":"POST /api/v1/compendium"},{"location":"api/endpoints/#qa-endpoint","text":"","title":"QA Endpoint"},{"location":"api/endpoints/#post-apiv1qa","text":"Generate question-answer pairs from markdown content. Request Body: { \"markdown_content\" : \"# Einstein\\n\\nAlbert Einstein war...\" , \"config\" : { \"num_pairs\" : 10 , \"max_answer_length\" : 200 } }","title":"POST /api/v1/qa"},{"location":"api/endpoints/#pipeline-endpoint","text":"","title":"Pipeline Endpoint"},{"location":"api/endpoints/#post-apiv1pipeline","text":"Complete end-to-end processing combining all three endpoints. Request Body: { \"text\" : \"Input text for processing\" , \"config\" : { \"linker\" : { \"MODE\" : \"generate\" , \"MAX_ENTITIES\" : 15 }, \"compendium\" : { \"length\" : 8000 , \"enable_citations\" : true }, \"qa\" : { \"num_pairs\" : 12 , \"max_answer_length\" : 300 } } } Response: { \"original_text\" : \"Input text\" , \"linker_output\" : { ... }, \"compendium_output\" : { ... }, \"qa_output\" : { ... }, \"pipeline_statistics\" : { \"total_processing_time\" : 45.2 , \"steps_completed\" : 3 , \"step_times\" : { \"linker\" : 12.3 , \"compendium\" : 28.1 , \"qa\" : 4.8 } } }","title":"POST /api/v1/pipeline"},{"location":"api/endpoints/#utils-endpoints","text":"","title":"Utils Endpoints"},{"location":"api/endpoints/#post-apiv1utilssynonyms","text":"Generate synonyms for a given term. Request Body: { \"term\" : \"Wissenschaft\" , \"max_synonyms\" : 5 } Response: { \"term\" : \"Wissenschaft\" , \"synonyms\" : [ \"Forschung\" , \"Wissenschaftlichkeit\" , \"Gelehrsamkeit\" ] }","title":"POST /api/v1/utils/synonyms"},{"location":"api/overview/","text":"API Reference \u00b6 The Entity Extraction Batch API provides four main endpoints for processing text and generating educational content. Base URL \u00b6 http://localhost:8000/api/v1 Authentication \u00b6 Currently, no authentication is required for the API endpoints. However, you need to configure the OPENAI_API_KEY environment variable for the service to function. Rate Limiting \u00b6 The API implements rate limiting to prevent abuse: - Default : 100 requests per minute per IP - Configurable via environment variables Response Format \u00b6 All API responses follow a consistent JSON format: { \"data\" : { ... }, \"metadata\" : { ... }, \"processing_time\" : 1.23 } Error Handling \u00b6 Errors are returned with appropriate HTTP status codes and descriptive messages: { \"detail\" : \"Error description\" , \"error_type\" : \"ValidationError\" , \"timestamp\" : \"2025-06-23T10:30:00Z\" } Endpoints Overview \u00b6 Endpoint Method Purpose /linker POST Extract entities and link to Wikipedia /compendium POST Generate educational content /qa POST Create question-answer pairs /pipeline POST Complete end-to-end processing /utils/synonyms POST Generate synonyms for terms Content Types \u00b6 All endpoints accept and return application/json content type.","title":"Overview"},{"location":"api/overview/#api-reference","text":"The Entity Extraction Batch API provides four main endpoints for processing text and generating educational content.","title":"API Reference"},{"location":"api/overview/#base-url","text":"http://localhost:8000/api/v1","title":"Base URL"},{"location":"api/overview/#authentication","text":"Currently, no authentication is required for the API endpoints. However, you need to configure the OPENAI_API_KEY environment variable for the service to function.","title":"Authentication"},{"location":"api/overview/#rate-limiting","text":"The API implements rate limiting to prevent abuse: - Default : 100 requests per minute per IP - Configurable via environment variables","title":"Rate Limiting"},{"location":"api/overview/#response-format","text":"All API responses follow a consistent JSON format: { \"data\" : { ... }, \"metadata\" : { ... }, \"processing_time\" : 1.23 }","title":"Response Format"},{"location":"api/overview/#error-handling","text":"Errors are returned with appropriate HTTP status codes and descriptive messages: { \"detail\" : \"Error description\" , \"error_type\" : \"ValidationError\" , \"timestamp\" : \"2025-06-23T10:30:00Z\" }","title":"Error Handling"},{"location":"api/overview/#endpoints-overview","text":"Endpoint Method Purpose /linker POST Extract entities and link to Wikipedia /compendium POST Generate educational content /qa POST Create question-answer pairs /pipeline POST Complete end-to-end processing /utils/synonyms POST Generate synonyms for terms","title":"Endpoints Overview"},{"location":"api/overview/#content-types","text":"All endpoints accept and return application/json content type.","title":"Content Types"},{"location":"architecture/overview/","text":"Architecture Overview \u00b6 The Entity Extraction Batch API follows a modern, modular architecture designed for maintainability, scalability, and testability. High-Level Architecture \u00b6 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 API Layer \u2502 \u2502 Core Logic \u2502 \u2502 Services \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2022 FastAPI \u2502\u25c4\u2500\u2500\u25ba\u2502 \u2022 Entity Proc. \u2502\u25c4\u2500\u2500\u25ba\u2502 \u2022 Wikipedia \u2502 \u2502 \u2022 Pydantic \u2502 \u2502 \u2022 Content Gen. \u2502 \u2502 \u2022 OpenAI \u2502 \u2502 \u2022 Rate Limiting \u2502 \u2502 \u2022 QA Generation \u2502 \u2502 \u2022 HTTP Clients \u2502 \u2502 \u2022 Validation \u2502 \u2502 \u2022 Pipeline Orch.\u2502 \u2502 \u2022 External APIs \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Models \u2502 \u2502 \u2502 \u2502 \u2022 Data Schemas \u2502 \u2502 \u2022 Validation \u2502 \u2502 \u2022 Serialization \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Directory Structure \u00b6 app/ \u251c\u2500\u2500 api/ # API layer \u2502 \u2514\u2500\u2500 v1/ # API version 1 \u2502 \u251c\u2500\u2500 linker.py # Entity linking endpoint \u2502 \u251c\u2500\u2500 compendium.py # Content generation endpoint \u2502 \u251c\u2500\u2500 qa.py # Q&A generation endpoint \u2502 \u251c\u2500\u2500 pipeline.py # Pipeline orchestration \u2502 \u2514\u2500\u2500 utils.py # Utility endpoints \u251c\u2500\u2500 core/ # Core business logic \u2502 \u251c\u2500\u2500 openai_wrapper.py # OpenAI integration \u2502 \u251c\u2500\u2500 settings.py # Configuration \u2502 \u2514\u2500\u2500 utils.py # Core utilities \u251c\u2500\u2500 models/ # Data models \u2502 \u251c\u2500\u2500 entity_models.py # Entity-related models \u2502 \u251c\u2500\u2500 compendium_models.py # Content models \u2502 \u2514\u2500\u2500 qa_models.py # Q&A models \u2514\u2500\u2500 services/ # External services \u2514\u2500\u2500 wikipedia/ # Wikipedia service \u251c\u2500\u2500 api/ # Wikipedia API client \u251c\u2500\u2500 fallbacks/ # Fallback strategies \u251c\u2500\u2500 utils/ # Wikipedia utilities \u2514\u2500\u2500 service.py # Main service class Design Principles \u00b6 1. Separation of Concerns \u00b6 API Layer : Handles HTTP requests, validation, and responses Core Logic : Contains business logic and processing algorithms Services : Manages external API integrations Models : Defines data structures and validation rules 2. Dependency Injection \u00b6 Services are injected into endpoints Easy to mock for testing Configurable via environment variables 3. Async/Await Pattern \u00b6 Non-blocking I/O operations Concurrent processing where possible Efficient resource utilization 4. Error Handling \u00b6 Custom exception hierarchy Proper error propagation Detailed logging with structured data Data Flow \u00b6 Entity Linking Pipeline \u00b6 Input Validation : Pydantic models validate request data Entity Extraction : OpenAI extracts/generates entities from text Wikipedia Linking : Entities are linked to Wikipedia articles Fallback Strategies : Multiple strategies for difficult entities Response Formatting : Structured response with metadata Content Generation Pipeline \u00b6 Entity Processing : Takes linked entities as input Content Generation : OpenAI generates educational content Citation Integration : Wikipedia sources are integrated Markdown Formatting : Output formatted as structured markdown Q&A Generation Pipeline \u00b6 Content Analysis : Analyzes markdown content structure Question Generation : Creates relevant questions Answer Extraction : Generates concise answers Quality Validation : Ensures Q&A pair quality Scalability Considerations \u00b6 Horizontal Scaling \u00b6 Stateless design enables easy horizontal scaling No shared state between requests Database-free architecture (external APIs only) Performance Optimization \u00b6 Async HTTP clients for external API calls Connection pooling for Wikipedia API Intelligent caching strategies Rate limiting to prevent abuse Monitoring & Observability \u00b6 Structured logging with Loguru Health check endpoints Processing time metrics Error tracking and reporting","title":"Overview"},{"location":"architecture/overview/#architecture-overview","text":"The Entity Extraction Batch API follows a modern, modular architecture designed for maintainability, scalability, and testability.","title":"Architecture Overview"},{"location":"architecture/overview/#high-level-architecture","text":"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 API Layer \u2502 \u2502 Core Logic \u2502 \u2502 Services \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2022 FastAPI \u2502\u25c4\u2500\u2500\u25ba\u2502 \u2022 Entity Proc. \u2502\u25c4\u2500\u2500\u25ba\u2502 \u2022 Wikipedia \u2502 \u2502 \u2022 Pydantic \u2502 \u2502 \u2022 Content Gen. \u2502 \u2502 \u2022 OpenAI \u2502 \u2502 \u2022 Rate Limiting \u2502 \u2502 \u2022 QA Generation \u2502 \u2502 \u2022 HTTP Clients \u2502 \u2502 \u2022 Validation \u2502 \u2502 \u2022 Pipeline Orch.\u2502 \u2502 \u2022 External APIs \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Models \u2502 \u2502 \u2502 \u2502 \u2022 Data Schemas \u2502 \u2502 \u2022 Validation \u2502 \u2502 \u2022 Serialization \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"High-Level Architecture"},{"location":"architecture/overview/#directory-structure","text":"app/ \u251c\u2500\u2500 api/ # API layer \u2502 \u2514\u2500\u2500 v1/ # API version 1 \u2502 \u251c\u2500\u2500 linker.py # Entity linking endpoint \u2502 \u251c\u2500\u2500 compendium.py # Content generation endpoint \u2502 \u251c\u2500\u2500 qa.py # Q&A generation endpoint \u2502 \u251c\u2500\u2500 pipeline.py # Pipeline orchestration \u2502 \u2514\u2500\u2500 utils.py # Utility endpoints \u251c\u2500\u2500 core/ # Core business logic \u2502 \u251c\u2500\u2500 openai_wrapper.py # OpenAI integration \u2502 \u251c\u2500\u2500 settings.py # Configuration \u2502 \u2514\u2500\u2500 utils.py # Core utilities \u251c\u2500\u2500 models/ # Data models \u2502 \u251c\u2500\u2500 entity_models.py # Entity-related models \u2502 \u251c\u2500\u2500 compendium_models.py # Content models \u2502 \u2514\u2500\u2500 qa_models.py # Q&A models \u2514\u2500\u2500 services/ # External services \u2514\u2500\u2500 wikipedia/ # Wikipedia service \u251c\u2500\u2500 api/ # Wikipedia API client \u251c\u2500\u2500 fallbacks/ # Fallback strategies \u251c\u2500\u2500 utils/ # Wikipedia utilities \u2514\u2500\u2500 service.py # Main service class","title":"Directory Structure"},{"location":"architecture/overview/#design-principles","text":"","title":"Design Principles"},{"location":"architecture/overview/#1-separation-of-concerns","text":"API Layer : Handles HTTP requests, validation, and responses Core Logic : Contains business logic and processing algorithms Services : Manages external API integrations Models : Defines data structures and validation rules","title":"1. Separation of Concerns"},{"location":"architecture/overview/#2-dependency-injection","text":"Services are injected into endpoints Easy to mock for testing Configurable via environment variables","title":"2. Dependency Injection"},{"location":"architecture/overview/#3-asyncawait-pattern","text":"Non-blocking I/O operations Concurrent processing where possible Efficient resource utilization","title":"3. Async/Await Pattern"},{"location":"architecture/overview/#4-error-handling","text":"Custom exception hierarchy Proper error propagation Detailed logging with structured data","title":"4. Error Handling"},{"location":"architecture/overview/#data-flow","text":"","title":"Data Flow"},{"location":"architecture/overview/#entity-linking-pipeline","text":"Input Validation : Pydantic models validate request data Entity Extraction : OpenAI extracts/generates entities from text Wikipedia Linking : Entities are linked to Wikipedia articles Fallback Strategies : Multiple strategies for difficult entities Response Formatting : Structured response with metadata","title":"Entity Linking Pipeline"},{"location":"architecture/overview/#content-generation-pipeline","text":"Entity Processing : Takes linked entities as input Content Generation : OpenAI generates educational content Citation Integration : Wikipedia sources are integrated Markdown Formatting : Output formatted as structured markdown","title":"Content Generation Pipeline"},{"location":"architecture/overview/#qa-generation-pipeline","text":"Content Analysis : Analyzes markdown content structure Question Generation : Creates relevant questions Answer Extraction : Generates concise answers Quality Validation : Ensures Q&A pair quality","title":"Q&amp;A Generation Pipeline"},{"location":"architecture/overview/#scalability-considerations","text":"","title":"Scalability Considerations"},{"location":"architecture/overview/#horizontal-scaling","text":"Stateless design enables easy horizontal scaling No shared state between requests Database-free architecture (external APIs only)","title":"Horizontal Scaling"},{"location":"architecture/overview/#performance-optimization","text":"Async HTTP clients for external API calls Connection pooling for Wikipedia API Intelligent caching strategies Rate limiting to prevent abuse","title":"Performance Optimization"},{"location":"architecture/overview/#monitoring-observability","text":"Structured logging with Loguru Health check endpoints Processing time metrics Error tracking and reporting","title":"Monitoring &amp; Observability"},{"location":"development/setup/","text":"Development Setup \u00b6 This guide will help you set up the development environment for the Entity Extraction Batch API. Prerequisites \u00b6 Python 3.13+ (recommended) Git for version control Docker (optional, for containerized development) OpenAI API Key for LLM functionality Local Development Setup \u00b6 1. Clone the Repository \u00b6 git clone https://github.com/your-org/entityextractorbatch.git cd entityextractorbatch 2. Create Virtual Environment \u00b6 # Using venv python -m venv .venv source .venv/bin/activate # On Windows: .venv\\Scripts\\activate # Or using conda conda create -n entityextractor python = 3 .13 conda activate entityextractor 3. Install Dependencies \u00b6 # Install in development mode with all dependencies pip install -e \".[dev]\" 4. Environment Configuration \u00b6 Create a .env file in the project root: # OpenAI Configuration OPENAI_API_KEY = your-openai-api-key-here OPENAI_TIMEOUT = 60 .0 # Application Settings DEBUG = true LOG_LEVEL = DEBUG # Rate Limiting RATE_LIMIT_REQUESTS = 100 RATE_WINDOW = 60 # Wikipedia API WIKIPEDIA_TIMEOUT = 30 .0 5. Pre-commit Hooks \u00b6 Set up pre-commit hooks for code quality: pre-commit install This will automatically run: - Ruff linting and formatting - MyPy type checking - YAML/TOML validation - Pytest (on commit) Running the Application \u00b6 Development Server \u00b6 # Start with auto-reload uvicorn app.main:app --reload --host 0 .0.0.0 --port 8000 # Or using the provided script python -m app.main Docker Development \u00b6 # Build development image docker build -t entityextractorbatch:dev . # Run with environment variables docker run -p 8000 :8000 \\ -e OPENAI_API_KEY = \"your-key\" \\ -e DEBUG = true \\ entityextractorbatch:dev Testing \u00b6 Running Tests \u00b6 # Run all tests pytest # Run with coverage pytest --cov = app --cov-report = html # Run specific test file pytest tests/test_linker.py # Run with verbose output pytest -v Test Structure \u00b6 tests/ \u251c\u2500\u2500 test_endpoints.py # API endpoint tests \u251c\u2500\u2500 test_linker.py # Entity linking tests \u251c\u2500\u2500 test_compendium.py # Content generation tests \u251c\u2500\u2500 test_qa.py # Q&A generation tests \u251c\u2500\u2500 test_pipeline.py # Pipeline orchestration tests \u251c\u2500\u2500 test_utils.py # Utility function tests \u2514\u2500\u2500 test_wikipedia_service.py # Wikipedia service tests Code Quality \u00b6 Linting and Formatting \u00b6 # Check code quality ruff check app/ # Auto-fix issues ruff check app/ --fix # Format code ruff format app/ # Type checking mypy app/ Code Quality Standards \u00b6 Line Length : 120 characters maximum Import Sorting : Automatic with ruff Type Hints : Required for all functions Docstrings : PEP 257 format for all public functions Error Handling : Custom exceptions with proper logging Documentation \u00b6 Building Documentation \u00b6 # Install documentation dependencies (included in dev dependencies) pip install -e \".[dev]\" # Build documentation mkdocs build # Serve locally with auto-reload mkdocs serve Documentation Structure \u00b6 docs/ \u251c\u2500\u2500 index.md # Main documentation page \u251c\u2500\u2500 api/ # API documentation \u2502 \u251c\u2500\u2500 overview.md # API overview \u2502 \u2514\u2500\u2500 endpoints.md # Detailed endpoint docs \u251c\u2500\u2500 architecture/ # Architecture documentation \u2502 \u2514\u2500\u2500 overview.md # System architecture \u2514\u2500\u2500 development/ # Development guides \u2514\u2500\u2500 setup.md # This file Contributing \u00b6 Workflow \u00b6 Create Feature Branch : git checkout -b feature/your-feature Make Changes : Follow code quality standards Run Tests : Ensure all tests pass Commit Changes : Pre-commit hooks will run automatically Push Branch : git push origin feature/your-feature Create Pull Request : Use the provided PR template Code Review Checklist \u00b6 [ ] All tests pass [ ] Code coverage maintained [ ] Type hints added [ ] Docstrings updated [ ] No linting errors [ ] Documentation updated if needed Troubleshooting \u00b6 Common Issues \u00b6 Import Errors # Ensure you're in the virtual environment source .venv/bin/activate # Reinstall in development mode pip install -e \".[dev]\" OpenAI API Errors # Check API key is set echo $OPENAI_API_KEY # Test API connectivity curl -H \"Authorization: Bearer $OPENAI_API_KEY \" \\ https://api.openai.com/v1/models Docker Issues # Clean Docker cache docker system prune -a # Rebuild without cache docker build --no-cache -t entityextractorbatch . Getting Help \u00b6 Check the API documentation Review architecture overview Open an issue on GitHub Contact the development team","title":"Setup"},{"location":"development/setup/#development-setup","text":"This guide will help you set up the development environment for the Entity Extraction Batch API.","title":"Development Setup"},{"location":"development/setup/#prerequisites","text":"Python 3.13+ (recommended) Git for version control Docker (optional, for containerized development) OpenAI API Key for LLM functionality","title":"Prerequisites"},{"location":"development/setup/#local-development-setup","text":"","title":"Local Development Setup"},{"location":"development/setup/#1-clone-the-repository","text":"git clone https://github.com/your-org/entityextractorbatch.git cd entityextractorbatch","title":"1. Clone the Repository"},{"location":"development/setup/#2-create-virtual-environment","text":"# Using venv python -m venv .venv source .venv/bin/activate # On Windows: .venv\\Scripts\\activate # Or using conda conda create -n entityextractor python = 3 .13 conda activate entityextractor","title":"2. Create Virtual Environment"},{"location":"development/setup/#3-install-dependencies","text":"# Install in development mode with all dependencies pip install -e \".[dev]\"","title":"3. Install Dependencies"},{"location":"development/setup/#4-environment-configuration","text":"Create a .env file in the project root: # OpenAI Configuration OPENAI_API_KEY = your-openai-api-key-here OPENAI_TIMEOUT = 60 .0 # Application Settings DEBUG = true LOG_LEVEL = DEBUG # Rate Limiting RATE_LIMIT_REQUESTS = 100 RATE_WINDOW = 60 # Wikipedia API WIKIPEDIA_TIMEOUT = 30 .0","title":"4. Environment Configuration"},{"location":"development/setup/#5-pre-commit-hooks","text":"Set up pre-commit hooks for code quality: pre-commit install This will automatically run: - Ruff linting and formatting - MyPy type checking - YAML/TOML validation - Pytest (on commit)","title":"5. Pre-commit Hooks"},{"location":"development/setup/#running-the-application","text":"","title":"Running the Application"},{"location":"development/setup/#development-server","text":"# Start with auto-reload uvicorn app.main:app --reload --host 0 .0.0.0 --port 8000 # Or using the provided script python -m app.main","title":"Development Server"},{"location":"development/setup/#docker-development","text":"# Build development image docker build -t entityextractorbatch:dev . # Run with environment variables docker run -p 8000 :8000 \\ -e OPENAI_API_KEY = \"your-key\" \\ -e DEBUG = true \\ entityextractorbatch:dev","title":"Docker Development"},{"location":"development/setup/#testing","text":"","title":"Testing"},{"location":"development/setup/#running-tests","text":"# Run all tests pytest # Run with coverage pytest --cov = app --cov-report = html # Run specific test file pytest tests/test_linker.py # Run with verbose output pytest -v","title":"Running Tests"},{"location":"development/setup/#test-structure","text":"tests/ \u251c\u2500\u2500 test_endpoints.py # API endpoint tests \u251c\u2500\u2500 test_linker.py # Entity linking tests \u251c\u2500\u2500 test_compendium.py # Content generation tests \u251c\u2500\u2500 test_qa.py # Q&A generation tests \u251c\u2500\u2500 test_pipeline.py # Pipeline orchestration tests \u251c\u2500\u2500 test_utils.py # Utility function tests \u2514\u2500\u2500 test_wikipedia_service.py # Wikipedia service tests","title":"Test Structure"},{"location":"development/setup/#code-quality","text":"","title":"Code Quality"},{"location":"development/setup/#linting-and-formatting","text":"# Check code quality ruff check app/ # Auto-fix issues ruff check app/ --fix # Format code ruff format app/ # Type checking mypy app/","title":"Linting and Formatting"},{"location":"development/setup/#code-quality-standards","text":"Line Length : 120 characters maximum Import Sorting : Automatic with ruff Type Hints : Required for all functions Docstrings : PEP 257 format for all public functions Error Handling : Custom exceptions with proper logging","title":"Code Quality Standards"},{"location":"development/setup/#documentation","text":"","title":"Documentation"},{"location":"development/setup/#building-documentation","text":"# Install documentation dependencies (included in dev dependencies) pip install -e \".[dev]\" # Build documentation mkdocs build # Serve locally with auto-reload mkdocs serve","title":"Building Documentation"},{"location":"development/setup/#documentation-structure","text":"docs/ \u251c\u2500\u2500 index.md # Main documentation page \u251c\u2500\u2500 api/ # API documentation \u2502 \u251c\u2500\u2500 overview.md # API overview \u2502 \u2514\u2500\u2500 endpoints.md # Detailed endpoint docs \u251c\u2500\u2500 architecture/ # Architecture documentation \u2502 \u2514\u2500\u2500 overview.md # System architecture \u2514\u2500\u2500 development/ # Development guides \u2514\u2500\u2500 setup.md # This file","title":"Documentation Structure"},{"location":"development/setup/#contributing","text":"","title":"Contributing"},{"location":"development/setup/#workflow","text":"Create Feature Branch : git checkout -b feature/your-feature Make Changes : Follow code quality standards Run Tests : Ensure all tests pass Commit Changes : Pre-commit hooks will run automatically Push Branch : git push origin feature/your-feature Create Pull Request : Use the provided PR template","title":"Workflow"},{"location":"development/setup/#code-review-checklist","text":"[ ] All tests pass [ ] Code coverage maintained [ ] Type hints added [ ] Docstrings updated [ ] No linting errors [ ] Documentation updated if needed","title":"Code Review Checklist"},{"location":"development/setup/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"development/setup/#common-issues","text":"Import Errors # Ensure you're in the virtual environment source .venv/bin/activate # Reinstall in development mode pip install -e \".[dev]\" OpenAI API Errors # Check API key is set echo $OPENAI_API_KEY # Test API connectivity curl -H \"Authorization: Bearer $OPENAI_API_KEY \" \\ https://api.openai.com/v1/models Docker Issues # Clean Docker cache docker system prune -a # Rebuild without cache docker build --no-cache -t entityextractorbatch .","title":"Common Issues"},{"location":"development/setup/#getting-help","text":"Check the API documentation Review architecture overview Open an issue on GitHub Contact the development team","title":"Getting Help"}]}